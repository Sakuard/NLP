{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f0d7d3-20e5-4739-b966-d53c7d024adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import asyncio\n",
    "import ollama\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39186f45-96ed-436a-85f1-f0b8d738be2c",
   "metadata": {},
   "source": [
    "## This block is for \"ChromaDB\" setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0553ada-a8c3-4533-9d26-72e54aae65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = \"docs\"\n",
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)\n",
    "collection = chroma_client.get_or_create_collection(name=collection)\n",
    "\n",
    "def heartbeat():\n",
    "    return chroma_client.heartbeat()\n",
    "\n",
    "def collection_add(i, embedding, document, metadata):\n",
    "    collection.add(\n",
    "        ids=[i],\n",
    "        embeddings=[embedding],\n",
    "        documents=[document],\n",
    "        metadatas=[metadata]\n",
    "    )\n",
    "\n",
    "def collection_query(query, n_results):\n",
    "    results = collection.query(\n",
    "        query_embeddings=query,\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return results\n",
    "\n",
    "def collection_reset():\n",
    "    while True:\n",
    "        data_ids = collection.peek()['ids']\n",
    "        if not data_ids:\n",
    "            break\n",
    "        for i in data_ids:\n",
    "            # print(i)\n",
    "            collection.delete(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db112a5-bb7f-4667-8b24-6f0421d0d4fb",
   "metadata": {},
   "source": [
    "## This block is for \"RAG pipeline related\" funciton\n",
    "- prompt_expansion: use LLM to gen more related prompt to evaluate the response precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4054423c-d6bb-4dbb-8f9a-42038bedbcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_expansion(query):\n",
    "    expansive_prompts = ollama.generate(\n",
    "        model=\"llama3\",\n",
    "        prompt=f\"請用繁體中文，以這個 prompt: '{query}' 為基礎，以 array list 的方式，產生出額外 5 個相關的提問 prompt，我需要的 response 格式為 ['第一個產生的相似提問', '第二個產生的相似提問', '第三個產生的相似提問'] 這樣即可，不需要額外的其他內容，注意，相似提問的內容請以繁體中文呈現為主\"\n",
    "    )\n",
    "    return expansive_prompts['response']\n",
    "\n",
    "def query_rerank(embedding, topk):\n",
    "    results = collection_query(embedding, topk)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866e8d19-01af-42b6-826d-03426c3cb308",
   "metadata": {},
   "source": [
    "## This block is for Application layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8275487-f6cb-4e79-91c1-273ef41d7457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extend: ['歐洲博士論文是否需要學習英文？', '歐洲大學PhD課程的時間長度是多少？', '歐洲 Ph.D.畢業生的職場發展前景如何？', '歐洲國家中的Ph.D.研究方向有哪些趨勢？', '歐洲大學PhD論文的格式和要求是什麼？']\n"
     ]
    }
   ],
   "source": [
    "query = \"歐洲 phd\"\n",
    "expansive_prompts = prompt_expansion(query)\n",
    "print(f\"extend: {expansive_prompts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f229b6a2-554c-494d-8efa-d3875144c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = ollama.embeddings(prompt=query,model=\"llama3\")[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0101431b-2392-4e4b-b2a0-0c218a810457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_query_result: [['- 歡迎來到成人頻道最真實的工程師Podcast- 在這裡會討論最新的科技發展、產業趨勢以及工程師質疑分享- 喜歡本頻道的聽眾請到EcoPodcast- 還有Spotify上面給我們五星的評價留言- 也分享給更多的朋友讓我們把想法傳遞給更多的人嗨大家好 歡迎來到今天的節目是Ted今天這一集一樣是一個橫跨歐亞大陸的生活- 今天我們要來分享的是一個非常重要的一個問題- 因為我們在這個世界上- 很多人都會覺得我們是一個很重要的一個人- 今天這一集一樣是一個橫跨歐亞大陸的一個錄音- 我們先歡迎今天的來賓 子緣- 嗨大家好 我是子緣- 大家如果想知道子緣出國的一些經歷的話- 歡迎回聽上一集- 那我們這一集會偏向是- 針對子緣的研究、研究風氣還有一些技術上- 特別是robotic的部分- 因為現在robotic是一個很非常火熱的一個領域- 那我們會有更多的分享- 那我們在一開始的時候- 可以請子緣再幫我們跟大家簡介一下自己嗎- 嗨大家好 我是子緣- 我現在在慕尼黑工業大學念博班- 那我之前是機械人- 然後在念電機 做了機器人相關研究- 然後再到一個科技公司- 做運動控制的研發工程師- 可以跟大家簡介一下- 目前在國外念博', '像說他們博士比較容易拿- 講絕經還是什麼的- 後來就跟老師說他就念到碩士就好- 美國的話我聽說比較多這樣的case- 因為美國他- 因為美國還是要修碩士的課程- 你有修到滿你就可以拿碩士的學位- 但德國其實博士班不用修課- 所以其實我們現在如果我 quit 了- 我其實也拿不到碩士學位- OK所以你這變相就是all in這樣- 對 all in- 沒有啦這其實就是現在的工作啦其實- 對大家也可以參考一下- 所以這也是一個選擇的點- 那像是你接下來- 因為我們聊過很多- 你說我知道子緣一直有從事這種研究- 未來往研究走的一個規劃- 那我不知道說你在這邊- 開始真的從事一個更深入的研究之後- 你未來會是怎麼樣規劃- 就比如說你畢業之後還是- 之後是要往研究走嗎- 比如說先做博後再做什麼注意教授之類的- 還是你會想要把- 因為我也是認識一些博士朋友- 他後來到業界的都有嗎- 你是怎麼樣的規劃- 首先我要先講就是現在的規劃都是現在的- 因為畢竟博士我可能五年的時間- 我有點難去預測我未來會幹嘛- 但我目前的想法是- 就是我是真的覺得- 教學就是對下一代的一些教學- 我是真的蠻有熱情的- 然後我之前也有到偏鄉去服務過-', '也慢慢看到這樣的一個需求也看到員工可能有心理壓力或精神健康的問題那他們也慢慢導入了一些方式來改善因此我也看得到某些公司他們確實也提供了一些所謂免費的心理諮商的資源喔那或是導入一些比方說一些平台讓員工能夠去尋求一些心理的服務等等這樣子可是其實你知道我我所看到的喔就是很多來看門診的我都問他說你們公司有沒有這一類的的資源那他們都說有有有可是他們都不願意去因為我覺得有一個問題在於是大家好像也不太願意在公司裡面開誠布公的或是讓別人知道說自己有這方面的困難那這個就是變成有一種很擔心一種被標籤化的一種一種擔憂他們會擔心自己被貼上有精神狀況的時候是不是就會不適任了所以這個就是另外一個很大的問題我也在想說如何讓這整個整個科技業的或是當代的這種職場文化能夠稍微能夠接納說有一些精神狀況的人這其實不容易啦真的很不容易其實我覺得這件事情難以避免就是真的是難以我覺得難以避免就雖然說我們我們會比較一次同仁的就覺得去這樣這樣子去想要這樣子去對待但如果今天一個比較傳統的人當他今天比如說牽扯到什麼更高壓的一個機會還是什麼那個近身的機會我覺得難免會被納入考量如果在在一些比較傳統的地方但或許一些文化比較開放的地方可能還好那我剛剛提到的是剛剛Pete', '靠北但是如果說你真的有需要告訴別人是一個蠻重要的一個心理抒發至少對我來說我覺得是蠻好也推薦大家可以這樣做因為不要像有些人他的個性是自己悶著那話就只能去消化之類的這可能也不太好那最後想請Peter給我們的聽眾朋友們一些建議如果說今天有幾個要素你可以總結今天想要有一個健康的心理健康身心健康狀態你認為哪幾個如果讓你挑三個最重要的點你會怎麼樣告訴你的門診的一些客戶或者說聽眾朋友們我覺得最重要是有一個休息時間Me time 自己的時間這個休息的定義也許很廣我覺得不一定是完全是躺在床上休息就是說你可以有自己的時間空間可以做自己喜歡的事情這是很重要的因為你知道我們今天講工程師的健康我們一直在講工程師面對的工作壓力其實從這個就是古典的就是比較社略學理論會去談說一個人的狀態他的問題是被異化了這馬克思說的這很簡單的道理我相信大家都可以有所感受就是異化就是人變得不是人人為什麼不是人呢因為人已經不是為了人的生存條件而活著我簡單講我所看到的工程師或是竹科員工是為了什麼活著是為了機器活著我們用盡無所不用其極的讓機器能夠順利的運作可是卻剝奪了我們人的時間跟精力這個難道不清楚嗎我們大家都非常在乎機器能夠穩定的運作各位今天在那個Compute', ' 不像說你今天去工作你不爽就投而已嘛- 不爽連結打開- 雖然說可以換教授- 但換教授是超級麻煩的一件事情- 對啊是啊- 博士更是一個四到五年的承諾嘛- 對啊你這個- 哇幹我覺得這是很屌的一件事情- 所以如果大家想要做這件事情的時候- 可以好好評估一下自己是什麼樣的人- 我覺得評估自己個性很重要- 能貴至值嘛- 就你知道自己不適合就不要陪人家玩- 像我就是絕對不會去念博士- 我這樣瞭解自己我真的是絕對不會念博士- 那個時候我有個記得我爸前陣子跟我說- 他說等我之後假設我三十幾歲- 我真的向我的規劃到財富自由的話- 可以考慮要不要再去念個博士- 我說我幹嘛還去念博士- 我今天對我去財富自由證明自己- 我就做我想做的事情我還進去幹什麼- 我還進去拿這張紙- 就是除非我很有興趣那就不一樣- 如果我有興趣不一樣- 但如果我是- 就我就不喜歡我還去讓我自己受苦- 對吧- 對其實我覺得我們就換個角度來講- 其實對學校方或是實驗室方- 他們也是要花五年去投資一千萬台幣在你身上- 所以他們也希望找到一個- 真的了解自己真的想要做這行的人進來- 所以我覺得就真的要- 你要知道自己很清楚想要什麼- 然後你如果自己不適合那不用念啊-', ' 你甚至要花錢去貼你的生活費的話- 我覺得壓力會很大- 尤其是四五年的一個過程- 對然後再來- 就是要很清楚知道自己為何而戰吧- 就是你真的會遇到太多- 就是很灰心喪志的時候- 你就很想也沒辦法放棄- 我現在也沒辦法放棄- 但說真的很多沮喪的時候- 那你如果你的意志不夠堅定的話- 我覺得會有點困難- 所以要很知道自己- 到底為什麼想出國念書- 為什麼想念- 就是我覺得不管是你要念碩士- 還是念博士都好- 就是真的剛剛我說的- 就是經濟跟家人要支持- 然後要知道自己為什麼要念書- 為什麼要念這個學位- 然後念完這個學位以後要幹嘛- 然後最後就是我覺得- 要對未來有天馬行空的憧憬- 但是要對當前也要有腳踏實地的決心- 就我覺得一步一步的去做- 但要樂觀的去看待未來的每一件事- 我覺得就心態吧- 就真的很重要- 哇這個結論下實在太好了- 謝謝謝謝- 因為其實我可以理解那種感覺啦- 那個時候我念碩士的時候- 我在那個時候簽教授的時候- 有點感覺說- 我記得我那時候還打電話給我一個朋友說- 幹我剛剛找好教授了- 怎麼感覺好像把自己兩年多- 我那時候提早大四就進碩士- 兩年多賣掉的感覺- 就突然有那種賣生氣簽下去的感覺-']]\n",
      "YES\n"
     ]
    }
   ],
   "source": [
    "topk = 6\n",
    "results = collection_query(embedding, topk)\n",
    "# print(results)\n",
    "tmp_query_result = []\n",
    "for d in results['documents']:\n",
    "    tmp_query_result.append(d)\n",
    "\n",
    "print(f\"tmp_query_result: {tmp_query_result}\")\n",
    "query_justify = ollama.generate(\n",
    "    model=\"llama3\",\n",
    "    prompt=f\"It's a YES/No question. 如果下列於 array list [] 內的內容，有任何可以是這個問題: '{query}' 的答案，請回答 yes,否則請回答 not\"\n",
    ")\n",
    "print(query_justify['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6940a9d0-3176-4967-a425-319c97a8fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the segmented content in an array list format:\n",
      "\n",
      "['大家好,歡迎來到成人頻道, source的東西拉進來然後在memory裡面形成一個方便query的cache就是以效能為核心的一個memory的solution這樣然後我們也有一個analysis service自己有一個query的語言叫做dex然後反正我們要去支援這樣的查詢這樣然後analysis service這個服務它已經超級久了大概20年就是它跟第一代的SQL service或是Excel是一起出現所以這個codebase已經超過20年但它被用在各式各樣不同的地方']\n",
      "\n",
      "['另外一件事情好像可以提的是我們每兩個月大概會要值班一週那那個值班基本上就是你會當第三線的客服就是你要負責去解就是客戶被Excel上來的ticket就是他遇到一些很奇怪的issue然後一般的客服解不了你就要負責看這樣']\n",
      "\n",
      "['我們也有很多什麼monitoring alert這種你也要負責去排除就是去看是false alarm還是真流regression這樣了解剛剛提到幾個點我這有幾個問題想問']\n",
      "\n",
      "['如果大家還不了解power BI的話你可以去參考陳真頻道的211幾那Stark有來分享他前陣子剛有出了一本書']\n",
      "\n",
      "['現在處理這個服務的codebase已經超過已經有20年那會有很多技術債嗎就是比如說你們要開發新的因為剛剛提到現在是micro service然後micro service這個概念顯然是比較後期的東西']\n",
      "\n",
      "['在前期那種打爆一整炮的是不是有點不太好讓你們拿出來弄就是技術債的話我自己體感是覺得會有一些東西被拖著但不會有就是沒有人就是沒有人知道那個地方要怎麼動']\n",
      "\n",
      "['就是這個倒還好的原因是因為他雖然超過20年但我們聽也有超就是好幾個是你知道從最一開始就在20幾年然後他們就那開始的codebase甚至是C就他還不是C++他是C所以就是現在還是可以看到我們code裡面有很多用一大堆macro然後那些macro拼拼湊湊其實就是C++的某一個modernize的功能']\n",
      "\n",
      "['這樣對對對但我比較少參與modernize的那個部分因為就是他比較需要對C的那一塊codebase很了解的人來進行']\n",
      "\n",
      "['總之比較新的大概都是用C++C sharp在弄了解如果這個轉換聽起來就很痛苦可能你要從C的概念然後再轉到OOP的這種東西你是要對兩個語言都需要很了解真的']\n",
      "\n",
      "['而且C在那邊指來指去指到不知道指到哪邊了我自己在看的時候我就是覺得很你知道在看一個我不知道IG金字塔的感覺就是他用一堆macro去堆出比如說他自動free東西就是OOP裡面會有的概念然後他用C去把它硬刻出來其實也蠻屌的對這個東西']\n",
      "\n",
      "['我要帶出來稍微分享一下就是我永遠記得有一次我跟那個就是我以前學校學長姐去錄應該兩三年前然後就是有那個比較偏機械演藝的學長他們就在那邊分享他現在在寫程式然後他就有一個人就說其實C也可以寫出C++的那些什麼繼承另外一個就跳出來說一定可以啊']\n",
      "\n",
      "['然後在那邊分享我心裡想說靠北啊我當然知道可以啊有沒有人會這樣用而已啊真的就是如果你現在2024年還在做什麼事情這真的自找麻煩耶我覺得對啊']\n"
     ]
    }
   ],
   "source": [
    "test_content = \"大家好,歡迎來到成人頻道,最真實的工程師Podcast在這裡會討論最新的科技發展、產業趨勢以及工程師質素分享喜歡本頻道的聽眾請到Echo Podcasts還有Spotify上面給我們五星的評價留言也分享給更多的朋友,讓我們把想法傳遞給更多的人嗨大家好,歡迎來到今天的節目,我是Ted今天這個開頭,我會講一下我自己的想法我自己的想法,我自己的想法我自己的想法,我自己的想法我自己的想法,我自己的想法大家好,我是Ted今天這個開頭,我已經吃了兩次螺絲其實剛剛發現好像也沒有錄好,但沒插算的反正我們已經一陣子沒有錄音了但因為頻道最近在做一些我們希望在內容上的一些調整以及我們重新去找一些來賓等等還有我們之後的一些計畫很快就會跟大家公佈但我們還是一樣,只要有好的內容還有一些很酷的來賓他們的經歷我們都希望能夠邀請他們與大家一起分享今天這位來賓是我自己算是有一次因緣際會看到他的表演我覺得非常非常有趣那也很有這個榮幸可以來邀請到他與我們聊聊他的經歷那我們事不宜遲,先歡迎今天的來賓,藍恩嗨,大家好,我是藍恩我覺得這個是我等一下再跟大家講為什麼我會這麼的開心有這個機會但在開始之前還是請藍恩先幫我們向觀眾介紹一下自己藍恩這個名字比較主要是用在喜劇院上然後反正我平常的工作是現在在微軟當軟體工程師然後我帶的Team是Power BI Team就是產品是Power BI然後Power BI底下的一個做Micro Service的Team叫做Analysis Service Team酷酷酷那剛剛聽到一個關鍵字喜劇演員我就是在那個有一次在那個多多人的那個宴他就是在蘋果那一位嘛然後我就有看到他們的一個笑話上的互動然後聽到這個笑話就覺得這個絕對是我們說什麼這是絕對是同行才能夠寫出來的嘛一定不是外面的一個路邊的人可以寫出來然後我就會找說那到底是哪一位表演者這麼有才那我們就發現了藍恩的表演然後我也看了一些他在YouTube上面的影片我覺得相當的酷可以跟大家分享一下說當時就是你這樣穿插這是一下子工程師一下子喜劇演員你覺得你的生活就是現在的比重是什麼哇現在的比重我覺得就經歷上來說的話可能是maybe是2比1嘛就是工作2然後喜劇1但是反正我心態上好像比較偏一個槓鈴策略就是反正我90%會壓在工作上就是確保工作是就是在一個合理的順利的穩定的進行的狀態下然後10%就是壓在喜劇這邊就是他很花精力但是獲得的金錢上的回報很少但是蠻有趣的所以就一直想要去做他這樣你的那個認識我的路徑真的是非常特別就是我真的是史上唯一一個就是透過Dudu Man的那個Rose1n的笑話發現這件事情蠻特別的沒有想過還有這個路線可是我們一聽到就知道說你知道有些人家不是說什麼是什麼行啊來之類的反正就是我們一聽到就覺得這個一定是你一定是要懂一點東西你才有辦法你才有辦法講出這些東西嘛然後就天線都翹起來我們就說可以了解一下其實確實我們剛剛在開始錄音之前跟藍暗聊了一下就覺得真的就是很其實我就覺得很發現就是很很像同溫層相近的可能我們在學生時候還是出社會可能遇到的人也都是很類似的人因為包括你剛剛提到槓鈴策略這也是我們自己一直以來都在強調我們在投資上也都是用槓鈴策略在做就是一定要讀一些報集嘛然後這種媒體某一個程度就是槓鈴的比端嘛就突然可能一些莫名其妙好處從天上掉下來之類的這個就是90%壓大盤一帖然後10%跑去買那個薰衣貨幣大概就是類似這種感覺對對對但我的槓鈴比較大便宜一點我的薰衣貨幣不只10%當然大家講的沒錯對這其實就是這個概念那我覺得其實在生活中槓鈴的一端就保保你自己不進公園但是另外一端其實就是生活中不論是你金錢上的報集還是你體驗上的報集還是各種你意想不到的好事可能會是出現在那一個端點那我們還是今天這一集會著重在工程師相關那當然我們本身是創作者也很希望可以跟藍恩聊聊更多那會在下一集再跟大家分享那可以請藍恩跟大家介紹一下你在微軟的角色跟你日常的工作職責大概是哪些嗎好我講的比剛剛的詳細一點就是反正現在微軟基本上就是軟體工程師就是做的事情就是一般的規劃feature然後寫code這樣然後剛說做的是analysis service就是整個power BI這個做這個軟體以防大家不知道什麼是power BI總之你可以把它想像成如果從來沒聽過的話你可以想像成是Excel不是有一個就是畫圖表的功能嗎然後你把那個功能複雜大概100倍就是power BI的長相就是它做的事情就是主要是focus在資料視覺化的部分然後它複雜的點是在於說你可以同時導入很多個data source就不同的data base或者是你想要從網頁裡面去撈資料或者是你有一些檔案類的或者是你local的file它可以透過gateway再forward到power BI上就是反正資料來源很複雜然後你可以對圖表做的權限控管也很複雜所以總之就是一切都可以高度客製化的狀態所以就是反正它是一個500多個人500多個RD在開發的一個軟體這樣然後我負責底下的這個micro service叫analysis service它主要是負責跟data source去做接觸就是我們會把data source的就是不同data source的東西拉進來然後在memory裡面形成一個方便query的cache就是以效能為核心的一個memory的solution這樣然後我們也有一個analysis service自己有一個query的語言叫做dex然後反正我們要去支援這樣的查詢這樣然後analysis service這個服務它已經超級久了大概20年就是它跟第一代的SQL service或是Excel是一起出現所以這個codebase已經超過20年但它被用在各式各樣不同的地方這樣所以反正基本上就是在裡面去開發新的feature這樣然後另外一件事情好像可以提的是我們每兩個月大概會要值班一週那那個值班基本上就是你會當第三線的客服就是你要負責去解就是客戶被Excel上來的ticket就是他遇到一些很奇怪的issue然後一般的客服解不了你就要負責看這樣然後我們也有很多什麼monitoring alert這種你也要負責去排除就是去看是false alarm還是真流regression這樣了解剛剛提到幾個點我這有幾個問題想問我先跟大家講如果大家還不了解power BI的話你可以去參考陳真頻道的211幾那Stark有來分享他前陣子剛有出了一本書那剛剛提到說你現在處理這個服務的codebase已經超過已經有20年那會有很多技術債嗎就是比如說你們要開發新的因為剛剛提到現在是micro service然後micro service這個概念顯然是比較後期的東西那在前期那種打爆一整炮的是不是有點不太好讓你們拿出來弄就是技術債的話我自己體感是覺得會有一些東西被拖著但不會有就是沒有人就是沒有人知道那個地方要怎麼動就是這個倒還好的原因是因為他雖然超過20年但我們聽也有超就是好幾個是你知道從最一開始就在20幾年然後他們就那開始的codebase甚至是C就他還不是C++他是C所以就是現在還是可以看到我們code裡面有很多用一大堆macro然後那些macro拼拼湊湊其實就是C++的某一個modernize的功能所以其實我們除了在推新的feature之外一直有一個就是在background在做的事情是去modernize很多東西同時在reflect一些舊的東西這樣對對對但我比較少參與modernize的那個部分因為就是他比較需要對C的那一塊codebase很了解的人來進行但總之比較新的大概都是用C++C sharp在弄了解如果這個轉換聽起來就很痛苦可能你要從C的概念然後再轉到OOP的這種東西你是要對兩個語言都需要很了解真的而且C在那邊指來指去指到不知道指到哪邊了我自己在看的時候我就是覺得很你知道在看一個我不知道IG金字塔的感覺就是他用一堆macro去堆出比如說他自動free東西就是OOP裡面會有的概念然後他用C去把它硬刻出來其實也蠻屌的對這個東西我要帶出來稍微分享一下就是我永遠記得有一次我跟那個就是我以前學校學長姐去錄應該兩三年前然後就是有那個比較偏機械演藝的學長他們就在那邊分享他現在在寫程式然後他就有一個人就說其實C也可以寫出C++的那些什麼繼承另外一個就跳出來說一定可以啊然後在那邊分享我心裡想說靠北啊我當然知道可以啊有沒有人會這樣用而已啊真的就是如果你現在2024年還在做什麼事情這真的自找麻煩耶我覺得對啊就是有時候真的是一兩句話要聽到這個人是不是來搞笑的不過這也是感覺還是蠻酷的一個經歷\"\n",
    "content_splitter = ollama.generate(\n",
    "    model=\"llama3\",\n",
    "    prompt=f\"需求：請以這段 content:'{test_content}' 為基礎，以 array list 的方式，對這個 content 做 data chunk。Response： ['第一段chunk','第二段chunk','第三段chunk',.....'第Ｎ段chunk']\"\n",
    ")\n",
    "\n",
    "print(content_splitter['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00c1f81f-6877-4dd9-8cab-c849a7ce285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2dataset = './dataset/'\n",
    "def read_documents_from_directory(directory):\n",
    "    documents = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                documents.append(file.read())\n",
    "                filenames.append(filename)\n",
    "    return documents, filenames\n",
    "\n",
    "documents, filenames = read_documents_from_directory(path2dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e010d21-ad31-43e6-a167-128585536b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_size = 512\n",
    "shift_size = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09988e2d-3862-4c24-b79b-06a472be1008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP227___德國讀電機博士_在職申請甘苦談_海外留學的心境_ft__子源.txt\n",
      "chunk: 大家好,歡迎來到成人頻道最真實的工程師Podcast在這裡會討論最新的科技發展產業趨勢以及工程師質素分享喜歡本頻道的聽眾請到Echo Podcast還有Spotify上面給我們五星的評價留言也分享給更多的朋友讓我們把想法傳遞給更多的人嗨大家好,歡迎來到今天的節目我是Ted,好,今天這一集我相信是一個很難得的一個機會讓我們可以去做更多的事情所以今天就分享到這裡我相信是一個如果你對海外的文化或者是一些他們的一些狀況感興趣的,不能錯過這一集那今天很開心可以邀請到我學弟來這裡跟大家一起分享那先歡迎今天的來賓子緣嗨大家好,我是子緣其實子緣之前有來過在很上古幾所,很久之前28,我記得28是不是對,印象中超級久對,大家有興趣可以去看一下28,靠北,28那時候那時候那時候我也才,我剛出社會沒多久對不對,好像是,不對啊你應該只有找半年或一年吧哦,對對對,你們有研剔你們有研剔對不對,所以其實我們出社會時間沒有差到很久那時候我才剛進我前公司然後分享我前公司的東西跟機械系的一些念機械系的一些過程哦,對對對,講到這個然後這個有印象,對,哦,長大好久以前時間就超快真的,好快,34年我每次做很多,大家都做蠻多不一樣的事情,我覺得反正時間就\n",
      "sumerize: Here is the array list with three keyphrases:\n",
      "\n",
      "['工程師Podcast', '技術發展', '產業趨勢']\n",
      "chunk: 差到很久那時候我才剛進我前公司然後分享我前公司的東西跟機械系的一些念機械系的一些過程哦,對對對,講到這個然後這個有印象,對,哦,長大好久以前時間就超快真的,好快,34年我每次做很多,大家都做蠻多不一樣的事情,我覺得反正時間就是這樣,維持體驗維持生活,維持自己想做的事就是,我覺得人生,反正人生本來就沒什麼意義那大家就是在找尋意義的過程裡面,就會感覺到一些踏實開始的時候可以請子緣跟大家簡單自我介紹一下如果有聽過遠古極速的人的話那可能有聽過這段,但是有一些更新了,我大學的時候是在成大機械然後,碩班到成大電機做一些機器人相關的研究,那畢業之後我就,就像Ted剛剛說的就是,我們到我到研剔,然後在新代科技,就我的前公司去做研發工程師的一個工作,那主要是在寫一些就是機器人,工具機的一些運動控制的演算法,那在那邊過了兩年多,快三年之後,然後我現在來到慕尼黑工業大學,念博士班對,然後剛來到這邊半年等一下大家,可以跟大家分享你是怎麼出國,因為你出國的那些準備,有一些我也有大概了解到吧,就是你一邊工作一邊寫論文,那時候覺得是挺屌的,可以跟大家分享一下但在那之前,可以跟大家分享一下說,你是什麼時候什麼動機,因為畢竟你也先開始先去打工\n",
      "sumerize: ['機械系', '人生', '出國']\n",
      "chunk: ,可以跟大家分享你是怎麼出國,因為你出國的那些準備,有一些我也有大概了解到吧,就是你一邊工作一邊寫論文,那時候覺得是挺屌的,可以跟大家分享一下但在那之前,可以跟大家分享一下說,你是什麼時候什麼動機,因為畢竟你也先開始先去打工嘛,那什麼動機讓你開始決定,你要出國其實一開始我在念碩班的時候最一開始是想念第二個碩士,那那個時候想法就只是很簡單,就覺得沒有出過國,然後我有個雙胞胎弟弟,然後他那時候已經在國外念書了,我就覺得那個很有趣,然後我那時候實習的時候也接觸到很多海歸的人我就覺得,如果可以在國外念書的話應該是會應該人生體驗會很不一樣,所以就想去試試看,但是到研究所過完之後就開始發現自己其實好像也不排斥做研究,然後做出來就是那個時候有做出一點成績然後也有被用來寫在專利上然後就覺得,應該自己應該也有機會去念博士,然後再到後來就這個想法一直有在想在心裡面吧,然後結果到試到公司之後我開始真的在做研發然後也大概熟悉產業界的研發工程是以我們這個領域運動工程這個領域大概在幹嘛之後呢我們公司剛好進來了兩個博士班的學生,然後這兩個博士班的學生我在跟他們接觸之後都覺得跟碩士蠻不太一樣他們都有辦法從無到有的去跟你用很基礎的物理、數學去\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (f, d) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(filenames, documents)):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(f)\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mprocess_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# response = ollama.embeddings(model=\"llama3\", prompt=d)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# embedding = response[\"embedding\"]\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# print(embedding)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# metadata = {\"type\":\"podcast\", \"name\":\"techporn\", \"ids\":f}\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# print(metadata)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# collection_add_v2(str(i), embedding, d, metadata)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m, in \u001b[0;36mprocess_document\u001b[0;34m(doc, model)\u001b[0m\n\u001b[1;32m      9\u001b[0m chunk \u001b[38;5;241m=\u001b[39m doc[start:end]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m sumerize \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m請用繁體中文，以這個 prmopt: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchunk\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m 為基礎，以 array list 的方式，給我包含三個關鍵字的 array list，這樣的回覆: [\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m第一個產生的關鍵字\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m第二個產生的關鍵字\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m第三個產生的關鍵字\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]，你唯一能回覆給我的內容只有 array list，其餘包含 Here is the keyphrase 這些協助說明都不允許\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msumerize: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msumerize[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# response = ollama.embeddings(model=model, prompt=chunk)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# embeddings.append(response[\"embedding\"])\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# chunks.append(chunk)\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/ollama/_client.py:127\u001b[0m, in \u001b[0;36mClient.generate\u001b[0;34m(self, model, prompt, system, template, context, stream, raw, format, images, options, keep_alive)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model:\n\u001b[1;32m    125\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmust provide a model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/generate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemplate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m_encode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeep_alive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m  \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/ollama/_client.py:98\u001b[0m, in \u001b[0;36mClient._request_stream\u001b[0;34m(self, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_stream\u001b[39m(\n\u001b[1;32m     93\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     94\u001b[0m   \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m     95\u001b[0m   stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     96\u001b[0m   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     97\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], Iterator[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]]]:\n\u001b[0;32m---> 98\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/ollama/_client.py:69\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m httpx\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[0;32m---> 69\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpx/_client.py:827\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    812\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    814\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    815\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    816\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    825\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    826\u001b[0m )\n\u001b[0;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/dev/nlp/rag/venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_document(doc, model=\"llama3\"):\n",
    "    length = len(doc)\n",
    "    start = 0\n",
    "    embeddings = []\n",
    "    chunks = []\n",
    "\n",
    "    while start < length:\n",
    "        end = min(start + token_size, length)\n",
    "        chunk = doc[start:end]\n",
    "        print(f\"chunk: {chunk}\")\n",
    "        sumerize = ollama.generate(\n",
    "            model = model,\n",
    "            prompt=f\"請用繁體中文，以這個 prmopt: '{chunk}' 為基礎，以 array list 的方式，給我包含三個關鍵字的 array list，這樣的回覆: ['第一個產生的關鍵字', '第二個產生的關鍵字', '第三個產生的關鍵字']，你唯一能回覆給我的內容只有 array list，其餘包含 Here is the keyphrase 這些協助說明都不允許\"\n",
    "        )\n",
    "        print(f\"sumerize: {sumerize['response']}\")\n",
    "        # response = ollama.embeddings(model=model, prompt=chunk)\n",
    "        # embeddings.append(response[\"embedding\"])\n",
    "        # chunks.append(chunk)\n",
    "        start += shift_size  # Move start forward by the shift size\n",
    "        \n",
    "\n",
    "    # return chunks\n",
    "    # return embeddings, chunks\n",
    "\n",
    "\n",
    "for i, (f, d) in enumerate(zip(filenames, documents)):\n",
    "    print(f)\n",
    "    process_document(d)\n",
    "\n",
    "    \n",
    "    # response = ollama.embeddings(model=\"llama3\", prompt=d)\n",
    "    # embedding = response[\"embedding\"]\n",
    "    # print(embedding)\n",
    "    # metadata = {\"type\":\"podcast\", \"name\":\"techporn\", \"ids\":f}\n",
    "    # print(metadata)\n",
    "    # collection_add_v2(str(i), embedding, d, metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
