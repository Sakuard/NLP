{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1f0d7d3-20e5-4739-b966-d53c7d024adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import asyncio\n",
    "import ollama\n",
    "import os\n",
    "import uuid\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335d2b16-05be-4942-a82a-d7cf0bcb8325",
   "metadata": {},
   "source": [
    "## This block is for \"global-variable\" setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e010d21-ad31-43e6-a167-128585536b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_size = 512\n",
    "shift_size = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39186f45-96ed-436a-85f1-f0b8d738be2c",
   "metadata": {},
   "source": [
    "## This block is for \"ChromaDB\" setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0553ada-a8c3-4533-9d26-72e54aae65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = \"docs\"\n",
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)\n",
    "collection = chroma_client.get_or_create_collection(name=collection)\n",
    "\n",
    "def heartbeat():\n",
    "    return chroma_client.heartbeat()\n",
    "\n",
    "def collection_add(i, embedding, document, metadata):\n",
    "    collection.add(\n",
    "        ids=[i],\n",
    "        embeddings=[embedding],\n",
    "        documents=[document],\n",
    "        metadatas=[metadata]\n",
    "    )\n",
    "\n",
    "def collection_query(query, n_results):\n",
    "    results = collection.query(\n",
    "        query_embeddings=query,\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return results\n",
    "\n",
    "def collection_reset():\n",
    "    while True:\n",
    "        data_ids = collection.peek()['ids']\n",
    "        if not data_ids:\n",
    "            break\n",
    "        for i in data_ids:\n",
    "            # print(i)\n",
    "            collection.delete(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f64fc-f43c-4c07-83db-d99df1d54629",
   "metadata": {},
   "source": [
    "## This block is for \"DB like controller\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "527f95a6-5986-4ea8-9ebb-017d157b515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_status(filename):\n",
    "    # 檢查文件是否存在且不為空\n",
    "    if not os.path.exists(filename) or os.stat(filename).st_size == 0:\n",
    "        return {}\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            return json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            # 如果 json 文件內容格式錯誤，返回空字典\n",
    "            return {}\n",
    "\n",
    "def save_status(filename, data):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "sql_file = 'sql.json'\n",
    "sql_data = load_status(sql_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dec0c0-29ed-4635-990e-87eecd042b31",
   "metadata": {},
   "source": [
    "## This block is for \"RAG pipeline related\" funciton\n",
    "- prompt_expansion: use LLM to gen more related prompt to evaluate the response precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4054423c-d6bb-4dbb-8f9a-42038bedbcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM prompt expansion >> 類似使用 \"many-hit\" 的方式來提高搜尋命中率\n",
    "def prompt_expansion(query):\n",
    "    expansive_prompts = ollama.generate(\n",
    "        model=\"llama3\",\n",
    "        prompt=f\"請用繁體中文，以這個 prompt: '{query}' 為基礎，以 array list 的方式，產生出額外 5 個相關的提問 prompt，我需要的 response 格式為 ['第一個產生的相似提問', '第二個產生的相似提問', '第三個產生的相似提問'] 這樣即可，不需要額外的其他內容，注意，相似提問的內容請以繁體中文呈現為主\"\n",
    "    )\n",
    "    return expansive_prompts['response']\n",
    "\n",
    "def query_rerank(embedding, topk):\n",
    "    results = collection_query(embedding, topk)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866e8d19-01af-42b6-826d-03426c3cb308",
   "metadata": {},
   "source": [
    "## This block is for Application layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c1f81f-6877-4dd9-8cab-c849a7ce285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2dataset = './dataset/'\n",
    "def read_documents_from_directory(directory):\n",
    "    documents = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                documents.append(file.read())\n",
    "                filenames.append(filename)\n",
    "    return documents, filenames\n",
    "\n",
    "documents, filenames = read_documents_from_directory(path2dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8275487-f6cb-4e79-91c1-273ef41d7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"歐洲遊學\"\n",
    "# expansive_prompts = prompt_expansion(query)\n",
    "# print(f\"extend: {expansive_prompts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f229b6a2-554c-494d-8efa-d3875144c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = ollama.embeddings(prompt=query,model=\"llama3\")[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0101431b-2392-4e4b-b2a0-0c218a810457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_query_result: [['意義不太大不知道發論文,所以我很早就知道幹我超討厭我超討厭盧培和所以我從來都不太會真的不太會,就很煩,都是數學然後,因為我覺得研究比較像是單點突破你要把一個細節把它做出一些新的東西可是從工程師的角度,比如說以軟體工程的角度你要去優化一個系統你有非常多選擇那這個就變成說你今天是一個,Solver Engineer是一個total solution,但你做research變成說你在某一個很特別的一個part,你必須要挖得比別人更深所以我沒辦法做應該說,其實我也不太喜歡那請問子緣,你當時是發現自己有這方面的一個天賦或興趣嗎?其實講到這個我就有點有點不好意思因為說真的,我覺得說天賦嗎?我其實沒有很有天賦,我有看過那種真的研究狂人,他是真的就是無時無刻不在做研究然後我覺得我沒有那麼我不排斥,但是我也沒有到真的很狂熱那我覺得真的會想要念博士主要還是就是有我一些想做的事情然後再加上自己其實我會喜歡看著這個東西,然後想要去把它搞懂那這個搞懂的過程,其實就像Ted說的一樣可能像工作你有很多他是一個total solution,那其實研究某方面來說同樣的問題也有很多種不同的解決方式某種程度來說這也是一種total solutio', '但是他會先讓你有一個picture讓你知道說要到那個階段大概要經歷過哪一些事情,然後你可能要做哪些準備真的是去走一條就是有些人已經幫你除過草你可以在那裡可以稍走一點彎路這也是我們創這些做這些內容分享很重要的一個原因大部分的人除非你今天是馬斯克,你要射火箭沒有人射過,不然大部分樓部都有人走過所以如果你有人可以參考那當然是很好的一件事情我們會把子緣的聯絡方式都放在下面大家有興趣可以關注他的內容那我自己覺得大家可以可能每個人都有每個人不同的一個生活的軌跡但你或許沒辦法帶走他每個部分但你可以帶走他的一個態度我覺得子緣他在很多做事的方式大家可以參考因為我們認識很久,我知道他是一個非常努力的人那這種態度是我自己認為你或許沒有人家聰明你或許沒有人家有資源但是你可以比別人做得更努力那你一樣有機會拿到你喜歡的一個成果那我知道就是在這些大家在找這些資料的時候其實你很難去找到好的管道那我剛剛說了如果有錢人走過,你有一些路可以參考那我認為是蠻重要的那最後可以請子緣幫我們介紹你的自媒體你的一些分享內容大家可以怎麼樣找到你我現在自己就是對,有在經營一個Instagram然後主要就是分享三個主題就是歐洲留學,然後個人成長跟博士分享然後我分', '司新的信金流是不是,拿去租學生租別的那我不好說,我不知道,要問他們他們是二房東,所以管理起來比較麻煩我想說這麼捲的是不是不知道也是有可能,但我確定在國外感覺是滿好特別的一些體驗有沒有什麼體驗是你就是比較覺得不適應的,可能跟台灣你過去才發現,這種文化上有衝擊之類的這個首先衝擊就是下次誰在跟我講德國人準時的話你給我試試看第一個就是其實他們的公眾運輸超常出狀況就是你搭一班德國的火車你可以直接誤點兩小時,然後最後那班車還直接不見然後說,不好意思,我們沒辦法然後你只能再搭下一班然後你要再等個一個多小時這個是第一個就是,在歐洲應該說在德國,大家都很常遇到的狀況然後其實連他們這邊的人都很受不了但是就是沒辦法他們就擺爛這樣,然後再來我覺得如果講到文化上,其實我覺得有兩個地方滿值得分享的第一個就是語言語言真的隔閡太大了大家可能會覺得歐洲人,大家可能很會講英文對,他們普遍來說英文能力滿好的可是他們其實真的不太願意講英文而且聽說跟法國人比起來,德國人已經比較願意講而且慕尼亞也是一個國際城市可是,譬如說我在實驗室他們很常會講德文,就會突然一群人就一起,聚在一起,然後講德文然後也不管旁邊的人聽不聽得懂這個有時候其實會還滿讓人滿挫折的吧']]\n",
      "A simple one!\n",
      "\n",
      "My answer is: **YES**\n"
     ]
    }
   ],
   "source": [
    "topk = 3\n",
    "results = collection_query(embedding, topk)\n",
    "# print(results)\n",
    "tmp_query_result = []\n",
    "for d in results['documents']:\n",
    "    tmp_query_result.append(d)\n",
    "\n",
    "print(f\"tmp_query_result: {tmp_query_result}\")\n",
    "query_justify = ollama.generate(\n",
    "    model=\"llama3\",\n",
    "    prompt=f\"It's a YES/No question. 如果下列於 array list [] 內的內容，有任何可以是這個問題: '{query}' 的答案，請回答 yes,否則請回答 not\"\n",
    ")\n",
    "print(query_justify['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6940a9d0-3176-4967-a425-319c97a8fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the segmented content in an array list format:\n",
      "\n",
      "['大家好,歡迎來到成人頻道, source的東西拉進來然後在memory裡面形成一個方便query的cache就是以效能為核心的一個memory的solution這樣然後我們也有一個analysis service自己有一個query的語言叫做dex然後反正我們要去支援這樣的查詢這樣然後analysis service這個服務它已經超級久了大概20年就是它跟第一代的SQL service或是Excel是一起出現所以這個codebase已經超過20年但它被用在各式各樣不同的地方']\n",
      "\n",
      "['另外一件事情好像可以提的是我們每兩個月大概會要值班一週那那個值班基本上就是你會當第三線的客服就是你要負責去解就是客戶被Excel上來的ticket就是他遇到一些很奇怪的issue然後一般的客服解不了你就要負責看這樣']\n",
      "\n",
      "['我們也有很多什麼monitoring alert這種你也要負責去排除就是去看是false alarm還是真流regression這樣了解剛剛提到幾個點我這有幾個問題想問']\n",
      "\n",
      "['如果大家還不了解power BI的話你可以去參考陳真頻道的211幾那Stark有來分享他前陣子剛有出了一本書']\n",
      "\n",
      "['現在處理這個服務的codebase已經超過已經有20年那會有很多技術債嗎就是比如說你們要開發新的因為剛剛提到現在是micro service然後micro service這個概念顯然是比較後期的東西']\n",
      "\n",
      "['在前期那種打爆一整炮的是不是有點不太好讓你們拿出來弄就是技術債的話我自己體感是覺得會有一些東西被拖著但不會有就是沒有人就是沒有人知道那個地方要怎麼動']\n",
      "\n",
      "['就是這個倒還好的原因是因為他雖然超過20年但我們聽也有超就是好幾個是你知道從最一開始就在20幾年然後他們就那開始的codebase甚至是C就他還不是C++他是C所以就是現在還是可以看到我們code裡面有很多用一大堆macro然後那些macro拼拼湊湊其實就是C++的某一個modernize的功能']\n",
      "\n",
      "['這樣對對對但我比較少參與modernize的那個部分因為就是他比較需要對C的那一塊codebase很了解的人來進行']\n",
      "\n",
      "['總之比較新的大概都是用C++C sharp在弄了解如果這個轉換聽起來就很痛苦可能你要從C的概念然後再轉到OOP的這種東西你是要對兩個語言都需要很了解真的']\n",
      "\n",
      "['而且C在那邊指來指去指到不知道指到哪邊了我自己在看的時候我就是覺得很你知道在看一個我不知道IG金字塔的感覺就是他用一堆macro去堆出比如說他自動free東西就是OOP裡面會有的概念然後他用C去把它硬刻出來其實也蠻屌的對這個東西']\n",
      "\n",
      "['我要帶出來稍微分享一下就是我永遠記得有一次我跟那個就是我以前學校學長姐去錄應該兩三年前然後就是有那個比較偏機械演藝的學長他們就在那邊分享他現在在寫程式然後他就有一個人就說其實C也可以寫出C++的那些什麼繼承另外一個就跳出來說一定可以啊']\n",
      "\n",
      "['然後在那邊分享我心裡想說靠北啊我當然知道可以啊有沒有人會這樣用而已啊真的就是如果你現在2024年還在做什麼事情這真的自找麻煩耶我覺得對啊']\n"
     ]
    }
   ],
   "source": [
    "test_content = \"大家好,歡迎來到成人頻道,最真實的工程師Podcast在這裡會討論最新的科技發展、產業趨勢以及工程師質素分享喜歡本頻道的聽眾請到Echo Podcasts還有Spotify上面給我們五星的評價留言也分享給更多的朋友,讓我們把想法傳遞給更多的人嗨大家好,歡迎來到今天的節目,我是Ted今天這個開頭,我會講一下我自己的想法我自己的想法,我自己的想法我自己的想法,我自己的想法我自己的想法,我自己的想法大家好,我是Ted今天這個開頭,我已經吃了兩次螺絲其實剛剛發現好像也沒有錄好,但沒插算的反正我們已經一陣子沒有錄音了但因為頻道最近在做一些我們希望在內容上的一些調整以及我們重新去找一些來賓等等還有我們之後的一些計畫很快就會跟大家公佈但我們還是一樣,只要有好的內容還有一些很酷的來賓他們的經歷我們都希望能夠邀請他們與大家一起分享今天這位來賓是我自己算是有一次因緣際會看到他的表演我覺得非常非常有趣那也很有這個榮幸可以來邀請到他與我們聊聊他的經歷那我們事不宜遲,先歡迎今天的來賓,藍恩嗨,大家好,我是藍恩我覺得這個是我等一下再跟大家講為什麼我會這麼的開心有這個機會但在開始之前還是請藍恩先幫我們向觀眾介紹一下自己藍恩這個名字比較主要是用在喜劇院上然後反正我平常的工作是現在在微軟當軟體工程師然後我帶的Team是Power BI Team就是產品是Power BI然後Power BI底下的一個做Micro Service的Team叫做Analysis Service Team酷酷酷那剛剛聽到一個關鍵字喜劇演員我就是在那個有一次在那個多多人的那個宴他就是在蘋果那一位嘛然後我就有看到他們的一個笑話上的互動然後聽到這個笑話就覺得這個絕對是我們說什麼這是絕對是同行才能夠寫出來的嘛一定不是外面的一個路邊的人可以寫出來然後我就會找說那到底是哪一位表演者這麼有才那我們就發現了藍恩的表演然後我也看了一些他在YouTube上面的影片我覺得相當的酷可以跟大家分享一下說當時就是你這樣穿插這是一下子工程師一下子喜劇演員你覺得你的生活就是現在的比重是什麼哇現在的比重我覺得就經歷上來說的話可能是maybe是2比1嘛就是工作2然後喜劇1但是反正我心態上好像比較偏一個槓鈴策略就是反正我90%會壓在工作上就是確保工作是就是在一個合理的順利的穩定的進行的狀態下然後10%就是壓在喜劇這邊就是他很花精力但是獲得的金錢上的回報很少但是蠻有趣的所以就一直想要去做他這樣你的那個認識我的路徑真的是非常特別就是我真的是史上唯一一個就是透過Dudu Man的那個Rose1n的笑話發現這件事情蠻特別的沒有想過還有這個路線可是我們一聽到就知道說你知道有些人家不是說什麼是什麼行啊來之類的反正就是我們一聽到就覺得這個一定是你一定是要懂一點東西你才有辦法你才有辦法講出這些東西嘛然後就天線都翹起來我們就說可以了解一下其實確實我們剛剛在開始錄音之前跟藍暗聊了一下就覺得真的就是很其實我就覺得很發現就是很很像同溫層相近的可能我們在學生時候還是出社會可能遇到的人也都是很類似的人因為包括你剛剛提到槓鈴策略這也是我們自己一直以來都在強調我們在投資上也都是用槓鈴策略在做就是一定要讀一些報集嘛然後這種媒體某一個程度就是槓鈴的比端嘛就突然可能一些莫名其妙好處從天上掉下來之類的這個就是90%壓大盤一帖然後10%跑去買那個薰衣貨幣大概就是類似這種感覺對對對但我的槓鈴比較大便宜一點我的薰衣貨幣不只10%當然大家講的沒錯對這其實就是這個概念那我覺得其實在生活中槓鈴的一端就保保你自己不進公園但是另外一端其實就是生活中不論是你金錢上的報集還是你體驗上的報集還是各種你意想不到的好事可能會是出現在那一個端點那我們還是今天這一集會著重在工程師相關那當然我們本身是創作者也很希望可以跟藍恩聊聊更多那會在下一集再跟大家分享那可以請藍恩跟大家介紹一下你在微軟的角色跟你日常的工作職責大概是哪些嗎好我講的比剛剛的詳細一點就是反正現在微軟基本上就是軟體工程師就是做的事情就是一般的規劃feature然後寫code這樣然後剛說做的是analysis service就是整個power BI這個做這個軟體以防大家不知道什麼是power BI總之你可以把它想像成如果從來沒聽過的話你可以想像成是Excel不是有一個就是畫圖表的功能嗎然後你把那個功能複雜大概100倍就是power BI的長相就是它做的事情就是主要是focus在資料視覺化的部分然後它複雜的點是在於說你可以同時導入很多個data source就不同的data base或者是你想要從網頁裡面去撈資料或者是你有一些檔案類的或者是你local的file它可以透過gateway再forward到power BI上就是反正資料來源很複雜然後你可以對圖表做的權限控管也很複雜所以總之就是一切都可以高度客製化的狀態所以就是反正它是一個500多個人500多個RD在開發的一個軟體這樣然後我負責底下的這個micro service叫analysis service它主要是負責跟data source去做接觸就是我們會把data source的就是不同data source的東西拉進來然後在memory裡面形成一個方便query的cache就是以效能為核心的一個memory的solution這樣然後我們也有一個analysis service自己有一個query的語言叫做dex然後反正我們要去支援這樣的查詢這樣然後analysis service這個服務它已經超級久了大概20年就是它跟第一代的SQL service或是Excel是一起出現所以這個codebase已經超過20年但它被用在各式各樣不同的地方這樣所以反正基本上就是在裡面去開發新的feature這樣然後另外一件事情好像可以提的是我們每兩個月大概會要值班一週那那個值班基本上就是你會當第三線的客服就是你要負責去解就是客戶被Excel上來的ticket就是他遇到一些很奇怪的issue然後一般的客服解不了你就要負責看這樣然後我們也有很多什麼monitoring alert這種你也要負責去排除就是去看是false alarm還是真流regression這樣了解剛剛提到幾個點我這有幾個問題想問我先跟大家講如果大家還不了解power BI的話你可以去參考陳真頻道的211幾那Stark有來分享他前陣子剛有出了一本書那剛剛提到說你現在處理這個服務的codebase已經超過已經有20年那會有很多技術債嗎就是比如說你們要開發新的因為剛剛提到現在是micro service然後micro service這個概念顯然是比較後期的東西那在前期那種打爆一整炮的是不是有點不太好讓你們拿出來弄就是技術債的話我自己體感是覺得會有一些東西被拖著但不會有就是沒有人就是沒有人知道那個地方要怎麼動就是這個倒還好的原因是因為他雖然超過20年但我們聽也有超就是好幾個是你知道從最一開始就在20幾年然後他們就那開始的codebase甚至是C就他還不是C++他是C所以就是現在還是可以看到我們code裡面有很多用一大堆macro然後那些macro拼拼湊湊其實就是C++的某一個modernize的功能所以其實我們除了在推新的feature之外一直有一個就是在background在做的事情是去modernize很多東西同時在reflect一些舊的東西這樣對對對但我比較少參與modernize的那個部分因為就是他比較需要對C的那一塊codebase很了解的人來進行但總之比較新的大概都是用C++C sharp在弄了解如果這個轉換聽起來就很痛苦可能你要從C的概念然後再轉到OOP的這種東西你是要對兩個語言都需要很了解真的而且C在那邊指來指去指到不知道指到哪邊了我自己在看的時候我就是覺得很你知道在看一個我不知道IG金字塔的感覺就是他用一堆macro去堆出比如說他自動free東西就是OOP裡面會有的概念然後他用C去把它硬刻出來其實也蠻屌的對這個東西我要帶出來稍微分享一下就是我永遠記得有一次我跟那個就是我以前學校學長姐去錄應該兩三年前然後就是有那個比較偏機械演藝的學長他們就在那邊分享他現在在寫程式然後他就有一個人就說其實C也可以寫出C++的那些什麼繼承另外一個就跳出來說一定可以啊然後在那邊分享我心裡想說靠北啊我當然知道可以啊有沒有人會這樣用而已啊真的就是如果你現在2024年還在做什麼事情這真的自找麻煩耶我覺得對啊就是有時候真的是一兩句話要聽到這個人是不是來搞笑的不過這也是感覺還是蠻酷的一個經歷\"\n",
    "content_splitter = ollama.generate(\n",
    "    model=\"llama3\",\n",
    "    prompt=f\"需求：請以這段 content:'{test_content}' 為基礎，以 array list 的方式，對這個 content 做 data chunk。Response： ['第一段chunk','第二段chunk','第三段chunk',.....'第Ｎ段chunk']\"\n",
    ")\n",
    "\n",
    "print(content_splitter['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09988e2d-3862-4c24-b79b-06a472be1008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(filename, doc, model=\"llama3\"):\n",
    "    print(f\"file: {filename}\")\n",
    "    length = len(doc)\n",
    "    start = 0\n",
    "    embeddings = []\n",
    "    chunks = []\n",
    "    i = 0\n",
    "\n",
    "    while start < length:\n",
    "        end = min(start + token_size, length)\n",
    "        chunk = doc[start:end]\n",
    "        # print(f\"chunk: {chunk}\")\n",
    "        sumerize = ollama.chat(\n",
    "            model = model,\n",
    "            messages= [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"我要你的回答只能是 Array-List object\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"[]\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"很好，請針對下列 content:'{chunk}，產生一個 Array-List 包含屬於 content 的七個 關鍵字\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        print(f\"sumerize: {sumerize['message']}\")\n",
    "        chunk_to_embedding = sumerize['message']['content']\n",
    "        chunk_metadata = {\"type\":\"podcast\",\"name\":\"techporn\",\"title\":filename,\"documents\":chunk,\"ids\":i}\n",
    "        # print(f\"{chunk_to_embedding}\")\n",
    "        print(f\"metadata: {chunk_metadata}\")\n",
    "        uid = uuid.uuid4()\n",
    "        # print(f\"ids:{uid}\")\n",
    "        print(\"--\"*20)\n",
    "        \n",
    "        response = ollama.embeddings(model=model, prompt=chunk_to_embedding)\n",
    "        embedding = response[\"embedding\"]\n",
    "        chunks.append(chunk_to_embedding)\n",
    "        collection_add(str(uid), embedding, chunk, chunk_metadata)\n",
    "        start += shift_size  # Move start forward by the shift size\n",
    "        i += 1\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "# for i, (f, d) in enumerate(zip(filenames, documents)):\n",
    "#     print(f)\n",
    "#     process_document(f, d)\n",
    "for i, (f, d) in enumerate(zip(filenames, documents)):\n",
    "    if sql_data.get(f, {}).get('status') != 'done':\n",
    "        process_document(f, d)\n",
    "        file_path = os.path.join(path2dataset, f)\n",
    "        sql_data[f] = {'filename': f, 'path': file_path, 'status': 'done'}\n",
    "    else:\n",
    "        print(f\"...Skipping [DONE] - {f}\")\n",
    "\n",
    "save_status(sql_file, sql_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe7811-02b1-4eea-b75e-5a503dc824bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
