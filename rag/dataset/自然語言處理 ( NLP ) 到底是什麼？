現在的世界已經來到一個資訊時代，除了工程領域之外，現在好像連人們印象中的人文學科也不得不轉型（屈服）於這個潮流，才能從爆炸的資訊中有效率的擷取資訊，解決各領域中的問題。

而提到資訊擷取，這個世界上最廣泛存在的其中一種資訊形式，就是語言和文字。語言中包含了各式各樣的資訊，從最小的聲音單位到組成詞語，詞語到句子並產生意義，這一切都交疊著無數的資訊。一個單純的母音可能就隱含著不同的情緒表達，不同的句子架構也可能傳達不同的立場和態度。如果能從語言這樣看似雜亂的系統中找到規律，我們就能利用這樣的規律或模式去對我們未知的事物進行推測，並做更有效的決策。

舉例來說：

行銷領域中，我們可以利用用戶在特定社群媒體上的發文形式和內容（甚至文法和標點符號）看出最近的流行趨勢是什麼以及人們如何談論這些潮流。這對於行銷工作者很有幫助，他們可以根據市場的狀況制定不同策略並考量什麼樣的決策才能最有效的增加公司收入。
銀行可以利用客戶在社群媒體上所留下的數位足跡（他們po過的文等等，即網路上的行為）來預估他們的信用評等。這樣的預估可以進一步用來預測該名客戶未來將遵守或破壞對銀行的信用。
在醫療領域中，透過某些人在網路上的發言以及搜尋的關鍵字內容等等，可以預測出他們為潛在憂鬱症患者的機率有多少。利用這些文字資訊甚至可以提早偵測某些人的精神傾向並預防防罪的發生。
以上簡單舉了三個不同領域的例子給大家參考，有趣的是大家可以發現其實這幾個領域都跟大家想像的傳統工程領域非常不同，無庸置疑的是自然語言的資料早就滲入大家生活的每個角落了。而不只是這些領域，其實像是新聞、廣告等等與社群媒體和文字強烈相關的產業更是免不了要碰到語言資訊的處理和統整。因此今天寫了這篇文即是想引入利用數位方法轉換語言成為可分析「資料」的手段 — 自然語言處理(Natural Language Processing).

自然語言處理101 — 兩種方法
自然語言即是自然演化而成的語言，基本上人類所使用的語言都算是自然語言(中文，英文，韓文，法文，手語等)。相較自然語言的則是人工語言，如程式語言(python, R, java, C++, C#等)。

在自然語言處理的發展過程中，大概有以下兩種演算法：

規則基準 (Rule-based Method)
機器學習 (Machine Learning)
規則基準 (Rule-based Method)
早期的自然語言處理比較偏向「規則基準」的做法(Rule-based method):
舉一個之前做過的語意角色標記的例子：

I want to help John carry his suitcase.
在這個句子當中，我們知道 “I” 是一個Agent(主事者)，John是一個beneficiary(受益者)，suitcase則是一個theme(受事者)。另外此句的核心動詞為help和carry(某些句法理論中可能會說是want，不過這裡先假設help和carry為核心動詞）。

如果我們想要標記這些語意角色，以rule-based method來說，可能就要事先制定一些規則，例如：

出現在句首的標記為agent
出現在want後兩個位置的字 (因為要跳過to) 為核心動詞
如果動詞為help，出現在help後兩個位置的字為第二個核心動詞
……….

大家看完一定會有一個感覺：「你怎麼知道每個句子都是這樣？」
沒錯，rule-based method最大的缺點就在於他沒辦法涵蓋所有的rules，由於語言是有無限性的，一個句子可以被無限延伸下去，所以現在制訂出來的rules不一定能適用於未來的句子。即便可以，也永遠都會有例外。所以這樣的方法並不是很有效率。(少數語言處理的工作可能還是會需要引入rule-based method，但並非主體。)

那這樣該怎麼辦？如果預先制定大量的規則去預測語言現象不是一個好主意的話，那有什麼是比較有效率的做法？其實反過來看，規則既然可以被事先制定，那在規則未知時，也一定可以從環境中被推論出來，意思就是：

使用大量的語料去歸納出其中的語言規則和資料模式

機器學習的引入(Statistical NLP)
相信大家最近不管在新聞或是社群媒體上，應該多少會有聽過「機器學習」(Machine Learning)這個名詞吧？近年來的自然語言處理多半是使用這種方法在進行文字資料的統整。

所以機器學習是什麼呢？基本概念就是

利用已知的資料找出其中規律，並對未知的資料進行推測。

講到這裡有沒有發現跟上面所提到的非常相似呢？因為是同一個概念！只是在自然語言處理當中，「已知的資料」就是我們日常生活中所講的所有話或我們在facebook, ig, ptt看到人家的那些發文、留言等等的文字資料。這些所有形式的文字資料蒐集在一起就可以構成所謂的「語料」。而當這些語料被大量收錄，整理成能被機器讀懂的資料集時，就成為了「語料庫」(corpus)

資料科學家在取得語料庫之後，可以進行不同的工作：

從語料庫中直接抓取需要分析的語料(例如某個時下流行的用語和其環境)
將語料庫中的部分資料訓練成一個語言模型，其中可能包含不同的句法和語意規則，以便之後進行相關推測
這些都是利用機器學習的方法將語料庫中所包含的大量資料訓練(train)成一個具有解釋力的模型後，未來應用於未知的資料上。

除了傳統的機器學習演算法外，大家可能也聽過近期開始發展蓬勃的深度學習演算法(deep learning) 。深度學習屬於機器學習底下的一個子集，目的相同，但進行運算的方式與傳統機器學習方法截然不同。深度學習是模仿人類神經元傳導訊息的結構所做出來的，其中也包含節點、和不同階層的概念。而深度學習更是大大推進了NLP所能做到的事，那些我們以後再談。

但機器學習的概念當然遠超不只如此，其中更包含複雜的數學原理，甚至厲害一點的人知道機器學習可以被分成監督式/非監督式的學習。至於這些細項，以後有機會再寫一篇文章跟大家分享吧。

與剛才提到的規則基準 (Rule-based) 的方法比起來，雖然機器學習的方法需要事先搜集語料才能進行，但由於模型是透過語料庫所建構出來，這也使得機器學習能更全面的涵蓋語料庫中的所有語言現象。簡單來說，比起規則基準的方法來說，機器學習更有概括性(generalizability)，這種方法套用於未知資料時，預測準確率也不會差太多;而相較之下rule-based method的那些規則只能適用於一小部分的語料，且永遠有加不完的規則。

底下提供一張我個人覺得畫得很好的圖，完美詮釋NLP與其他資訊科學領域的交集關係。


那今天的分享大概先到這裡，我只談到了一些有關自然語言處理最基本的概念及生活中應用的例子。但相信大家對於NLP實際的進行方式應該會感到好奇：從網路爬蟲(你可能會覺得那是什麼？)到斷詞及文本的表現等等
或NLP是怎麼辦到例如：文本的情緒分析？機器翻譯？語音辨識？文章分類？

這些之後會慢慢帶大家一起了解，在前面概念的部分都講完之後就會開始進入真正的NLP實作了！這當中會包含python的程式碼，如果以後工作或研究有需要這樣自然語言處理分析的朋友們，可以追蹤我的文章！

謝謝你們的閱讀～下回待續囉！